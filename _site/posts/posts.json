[
  {
    "path": "posts/2019-04-16-economists-visualization-mistakes-tidytuesday-apr-16-2019/",
    "title": "Economist''s Visualization Mistakes: TidyTuesday Apr 16 2019",
    "description": "Redrawing Economist's erroneous visualizations as described here - Mistakes,\nwe’ve drawn a few",
    "author": [
      {
        "name": "Aditya Mangal",
        "url": "https://www.linkedin.com/in/adityamangal410/"
      }
    ],
    "date": "2019-04-16",
    "categories": [
      "TidyTuesday"
    ],
    "contents": "\n\nContents\nIntroduction\nAnalysis\nLoad libraries\nAnalyzing Britain’s Political Left\nAnalyzing decline of dog weights\nAnalyzing Brexit data\nAnalyzing US trade deficit\nAnalyzing pension benefits\nAnalyzing EU balance\nAnalyzing papers published\n\n\nIntroduction\nFrom the article on Mistakes, we’ve drawn a few -\n“At The Economist, we take data visualisation seriously. Every week we publish around 40 charts across print, the website and our apps. With every single one, we try our best to visualise the numbers accurately and in a way that best supports the story. But sometimes we get it wrong. We can do better in future if we learn from our mistakes — and other people may be able to learn from them, too.”\nHere I will try and draw the improved plots as suggested by the article on economist or make a version I think is best. All this done towards the weekly social data project Tidy Tuesday.\nAnalysis\nLoad libraries\n\n\nShow code\n\nrm(list = ls())\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(ggplot2)\nlibrary(gridExtra)\nlibrary(scales)\ntheme_set(theme_light())\n\n\n\nAnalyzing Britain’s Political Left\n\n\nShow code\n\ncorbyn <- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/corbyn.csv\")\n\ncorbyn\n\n\n# A tibble: 6 x 2\n  political_group avg_facebook_likes\n  <chr>                        <dbl>\n1 Jeremy Corbyn                 5210\n2 Labour Party                   845\n3 Momentum                       229\n4 Owen Smith                     127\n5 Andy Burnham                   105\n6 Saving Labour                   56\n\n\n\nShow code\n\ncorbyn %>% \n  mutate(pct_likes = avg_facebook_likes/sum(avg_facebook_likes)) %>% \n  ggplot(aes(political_group, pct_likes, fill = \"red\")) + \n  geom_col(show.legend = FALSE) +\n  scale_y_continuous(labels = percent_format()) + \n  coord_flip() + \n  labs(y = \"% of likes over the political groups\",\n       x = \"Political Group\",\n       title = \"Percentage of Average Facebook likes for different political groups\",\n       caption = \"Based on data from The Economist about political left in Britain\")\n\n\n\n\nAnalyzing decline of dog weights\n\n\nShow code\n\ndogs <- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/dogs.csv\")\n\ndogs\n\n\n# A tibble: 10 x 3\n    year avg_weight avg_neck\n   <dbl>      <dbl>    <dbl>\n 1  2006       20.5     44.3\n 2  2007       20.0     43.8\n 3  2008       19.4     43.4\n 4  2009       19.2     43.2\n 5  2010       19.1     43.2\n 6  2011       19.0     43.1\n 7  2012       18.6     42.8\n 8  2013       18.5     42.8\n 9  2014       18.4     42.7\n10  2015       18.1     42.5\n\n\n\nShow code\n\ndogs %>% \n  mutate(year = as.factor(year),\n         weight_to_neck = avg_weight/avg_neck) %>% \n  ggplot(aes(x = year, y = weight_to_neck)) + \n  geom_line(aes(group = 1)) +\n  geom_point() +\n  labs(x = \"Year\",\n       y = \"Average Weight to Average Neck Ratio\",\n       title = \"Average Weight to Neck Ratio over Years\",\n       caption = \"Based on data from The Economist\")\n\n\n\n\nAnalyzing Brexit data\n\n\nShow code\n\nbrexit <- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/brexit.csv\")\n\nbrexit\n\n\n# A tibble: 85 x 3\n   date     percent_responding_right percent_responding_wrong\n   <chr>                       <dbl>                    <dbl>\n 1 02/08/16                       46                       42\n 2 09/08/16                       45                       44\n 3 17/08/16                       46                       43\n 4 23/08/16                       45                       43\n 5 31/08/16                       47                       44\n 6 14/09/16                       46                       43\n 7 12/10/16                       45                       44\n 8 20/10/16                       45                       44\n 9 15/11/16                       46                       43\n10 29/11/16                       44                       45\n# … with 75 more rows\n\n\n\nShow code\n\nbrexit %>% \n  mutate(date = dmy(date)) %>% \n  ggplot(aes(x = date)) + \n  geom_smooth(aes(y = percent_responding_right, colour = \"percent_responding_right\"), se = FALSE) + \n  geom_point(aes(y = percent_responding_right, colour = \"percent_responding_right\")) +\n  geom_smooth(aes(y = percent_responding_wrong, colour = \"percent_responding_wrong\"), se = FALSE) +\n  geom_point(aes(y = percent_responding_wrong, colour = \"percent_responding_wrong\")) + \n  scale_color_manual(labels = c(\"Right\", \"Wrong\"), values = c(\"blue\", \"red\")) + \n  labs(x = \"Date\",\n       y = \"Response Percentage\",\n       title = \"Response behaviour of people about Brexit over time on the question\",\n       subtitle = \"In hindsight, do you think Britain was right or wrong to vote to leave the EU?\",\n       caption = \"Based on data from The Economist\",\n       color = \"Response\")\n\n\n\n\nAnalyzing US trade deficit\n\n\nShow code\n\ntrade <- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/trade.csv\")\n\ntrade\n\n\n# A tibble: 22 x 3\n    year trade_deficit manufacture_employment\n   <dbl>         <dbl>                  <dbl>\n 1  1995  -33789500000              17244583.\n 2  1996  -39520200000              17236750 \n 3  1997  -49695500000              17417833.\n 4  1998  -56927400000              17560000 \n 5  1999  -68677100000              17322667.\n 6  2000  -83833000000              17265250 \n 7  2001  -83096100000              16440583.\n 8  2002 -103064900000              15256833.\n 9  2003 -124068154000              14508500 \n10  2004 -162254261500              14314750 \n# … with 12 more rows\n\n\n\nShow code\n\ntrade %>% \n  mutate(year = as.factor(year),\n         trade_deficit = trade_deficit/1000000000,\n         manufacture_employment = manufacture_employment/1000000) -> trade\n\ntrade %>% \n  ggplot(aes(x = year, y = trade_deficit, fill = \"trade_deficit\")) + \n  geom_col(show.legend = FALSE) + \n  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + \n  labs(x = \"Year\",\n       y = \"Trade Deficit in billions\",\n       title = \"US Trade Deficit over years\",\n       caption = \"Based on data from The Economist\") -> p1\n\ntrade %>% \n  ggplot(aes(x = year, y = manufacture_employment, color = \"manufacture_employment\")) + \n  geom_line(aes(group = 1), show.legend = FALSE) + \n  geom_point(show.legend = FALSE) + \n  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + \n  labs(x = \"Year\",\n       y = \"Manufacturing Employment in millions\",\n       title = \"Manufacturing Employment over years\",\n       caption = \"Based on data from The Economist\") -> p2\n\ngrid.arrange(p1, p2, nrow = 1)\n\n\n\n\nAnalyzing pension benefits\n\n\nShow code\n\npensions <- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/pensions.csv\")\n\npensions\n\n\n# A tibble: 35 x 3\n   country        pop_65_percent gov_spend_percent_gdp\n   <chr>                   <dbl>                 <dbl>\n 1 Australia               15.0                   5.2 \n 2 Austria                 18.8                  13.9 \n 3 Belgium                 18.2                  10.4 \n 4 Brazil                   7.84                 12   \n 5 Canada                  16.1                   4.31\n 6 Chile                   11                     3.25\n 7 Czech Republic          18.1                   9.09\n 8 Denmark                 19.0                   8.45\n 9 Estonia                 18.8                   6.99\n10 Finland                 20.5                  11.4 \n# … with 25 more rows\n\n\n\nShow code\n\npensions %>% \n  mutate(spend_per_head = gov_spend_percent_gdp/pop_65_percent) %>% \n  ggplot(aes(x = pop_65_percent, y = gov_spend_percent_gdp, color = country, size = spend_per_head)) + \n  geom_point(show.legend = FALSE) + \n  geom_text(aes(label = country), hjust = -0.15, vjust = 0, show.legend = FALSE) + \n  labs(x = \"Percent of population aged 65 or older\",\n       y = \"Percent of government spending on pension benefits as percent of GDP\",\n       title = \"Government Spend vs. Population over 65\",\n       subtitle = \"Size of point represents the spend per head\",\n       caption = \"Based on data from The Economist\")\n\n\n\n\nAnalyzing EU balance\n\n\nShow code\n\neu_balance <- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/eu_balance.csv\")\n\neu_balance\n\n\n# A tibble: 266 x 4\n   country account_type  year   value\n   <chr>   <chr>        <dbl>   <dbl>\n 1 Belgium current       2009  -3755 \n 2 Germany current       2009 141234 \n 3 Estonia current       2009    360 \n 4 Ireland current       2009  -7912.\n 5 Greece  current       2009 -29323 \n 6 Spain   current       2009 -46191 \n 7 France  current       2009 -10652 \n 8 Italy   current       2009 -29717 \n 9 Cyprus  current       2009  -1431 \n10 Latvia  current       2009   1463 \n# … with 256 more rows\n\n\n\nShow code\n\neu_balance %>% \n  mutate(year = as.factor(year),\n         account_type = as.factor(account_type),\n         country = as.factor(country)) %>% \n  group_by(year, account_type) %>% \n  mutate(perc = value/sum(value)) %>% \n  top_n(5, perc) %>% \n  ungroup() %>% \n  ggplot(aes(x = year, y = value, fill = country)) +\n  geom_col() + \n  facet_wrap(~account_type) +\n  labs(x = \"Year\",\n       y = \"Value in billions of euros\",\n       title = \"Top 5 countries per year and account type\",\n       subtitle = \"Based on percentage of balances\",\n       caption = \"Based on data from The Economist\")\n\n\n\n\nAnalyzing papers published\n\n\nShow code\n\nwomen_research <- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/women_research.csv\")\n\nwomen_research\n\n\n# A tibble: 60 x 3\n   country        field           percent_women\n   <chr>          <chr>                   <dbl>\n 1 Japan          Health sciences          0.24\n 2 Chile          Health sciences          0.43\n 3 United Kingdom Health sciences          0.45\n 4 United States  Health sciences          0.46\n 5 Mexico         Health sciences          0.46\n 6 Denmark        Health sciences          0.47\n 7 EU28           Health sciences          0.48\n 8 France         Health sciences          0.48\n 9 Canada         Health sciences          0.49\n10 Australia      Health sciences          0.5 \n# … with 50 more rows\n\n\n\nShow code\n\nwomen_research %>% \n  ggplot(aes(x = field, y = percent_women, color = country, size = percent_women)) + \n  geom_point() + \n  scale_size(guide = \"none\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + \n  labs(x = \"Field of study\",\n       y = \"Percentage of Women\",\n       title = \"Women among researchers with papers published 2011-15 as % of total by field of study for 12 countries\",\n       subtitle = \"Size of point also represents percentage of women\",\n       color = \"Country\",\n       caption = \"Based on data from The Economist\")\n\n\n\n\n\n\n\n",
    "preview": "https://lh3.googleusercontent.com/xNXkTy47bwg_XWNQbbqdO5Bk0hoOKmNZua683-YifaJSJaOFN-zsHi5yX-8LkJ4WAZJkhTGCv-kVyYJ8d0RdNXqfDODt3kypwC_nz3lfpNuuzo6m_CjOZhw0AGiHYbvqY8awympo929GydgtY0awlwqIHTtPlqFXj75IzOuR-vpbCtNgK_byginv9D34m7coAQGpdlHDQWUBo2dmaJSDKjvmGn5v4JxViYb6JYYmJDtMAn0SCEmMuz_HN50L_eW9oSXZEDH-Te-4boyPqAZFaor0DmzpxKpWtJsW0ewSqg3Ur6cj9p1VEi_Y9ur_i9fkOvE8WqyspLFG4fHRg2PcLIyAcx3P4l6NrRSiylKYO_1AJ3aXeQdSRmQZ4NRZoD26a2GxOAHi2OXUZScOOFHmC9PwsJ9ESMax8B6R7-CLwUJjvslxoCzYZfRypW7PEZpD-fAKO0hVk6EAyyDkWhFK9QJSHQc3-P6CVYJTzlyVao3iuqM0P7DTtP8WpL7mjYnmdSCV4fbviWZk_NGqnZPNVatM4bXZ1GVeiKlKbEr22HDBqkB0TQVKzWUp0Yp4ZY9XwqUJu_UnIZ8rbEeg88zsxRFGiG-NBkeBzBsThIIsz2Zn2Jv_qpadmxeLHOT5TRkgswOTF1TGTUw1v3v9xYZHTg8S0l4EkZELxNPeTU_kvYjV692_YqIvEn-GC2baEJj5y6kyCR1Od34zIpe6LysY9wDv-w=w750-h500-no",
    "last_modified": "2021-04-18T15:00:08-07:00",
    "input_file": "economists-visualization-mistakes-tidytuesday-apr-16-2019.utf8.md"
  },
  {
    "path": "posts/2018-02-18-where-does-your-medicine-come-from-makeovermonday-2018-week-8/",
    "title": "Where Does Your Medicine Come From?: MakeOverMonday 2018 Week 8",
    "description": "Goal of this Visualization task is to create a visualization for the Drug\nand Medicine Exports data for different countries.",
    "author": [
      {
        "name": "Aditya Mangal",
        "url": "https://www.linkedin.com/in/adityamangal410/"
      }
    ],
    "date": "2018-02-18",
    "categories": [
      "MakeOverMonday"
    ],
    "contents": "\n\nContents\nIntroduction\nAnalysis\nCleaning up workspace and loading required libraries\nObtaining Data\nScrubbing data\nExploring Data\n\n\nIntroduction\nGoal of this Visualization task is to create a visualization for the Drug and Medicine Exports data for different countries.\nIn this blog post, I’m trying to find the leading countries in Export across these 5 years.\nAnalysis\nCleaning up workspace and loading required libraries\n\n\nShow code\n\nrm(list = ls())\n\n\n\n\n\nShow code\n\nlibrary(tidyverse) #Data Wrangling\nlibrary(\"httr\")\nlibrary(readxl) #Data Ingestion\nlibrary(ggplot2) #Data Visualization\n\n\n\nObtaining Data\nReading and viewing the dataset\n\n\nShow code\n\nGET(\"https://query.data.world/s/utmlfljjzc2naoeielefxsf4fh5qkf\", write_disk(tf <- tempfile(fileext = \".xlsx\")))\n\n\n\nShow code\n\ndrugs <- read_excel(tf)\n\n\n\n\n\nShow code\n\ndrugs\n\n\n# A tibble: 1,100 x 3\n   Exporter                  Year `Exports (USD)`\n   <chr>                    <dbl>           <dbl>\n 1 World                     2013    326445385000\n 2 Germany                   2013     48493611000\n 3 Switzerland               2013     32337891000\n 4 Belgium                   2013     33329615000\n 5 France                    2013     27848920000\n 6 United States of America  2013     23098676000\n 7 United Kingdom            2013     20885936000\n 8 Ireland                   2013     18152573000\n 9 Italy                     2013     20898532000\n10 Netherlands               2013     13480651000\n# … with 1,090 more rows\n\nSummarizing and getting stats to better understand the dataset\n\n\nShow code\n\ndrugs %>% \n  glimpse()\n\n\nRows: 1,100\nColumns: 3\n$ Exporter        <chr> \"World\", \"Germany\", \"Switzerland\", \"Belgium\"…\n$ Year            <dbl> 2013, 2013, 2013, 2013, 2013, 2013, 2013, 20…\n$ `Exports (USD)` <dbl> 326445385000, 48493611000, 32337891000, 3332…\n\nShow code\n\ndrugs %>% \n  summary()\n\n\n   Exporter              Year      Exports (USD)      \n Length:1100        Min.   :2013   Min.   :0.000e+00  \n Class :character   1st Qu.:2014   1st Qu.:1.212e+05  \n Mode  :character   Median :2015   Median :7.393e+06  \n                    Mean   :2015   Mean   :3.315e+09  \n                    3rd Qu.:2016   3rd Qu.:3.293e+08  \n                    Max.   :2017   Max.   :3.405e+11  \n                                   NA's   :266        \n\nScrubbing data\nRemoving rows with NA for the purposes of this visualization\n\n\nShow code\n\ndrugs = drugs %>% \n  filter(!is.na(`Exports (USD)`))\n\n\n\nLet’s see overall which are the Countries with highest export over these 5 years.\n\n\nShow code\n\ndrugs %>% \n  group_by(Exporter) %>% \n  summarise(TotalExport = sum(`Exports (USD)`)) %>% \n  arrange(desc(TotalExport))\n\n\n# A tibble: 220 x 2\n   Exporter                   TotalExport\n   <chr>                            <dbl>\n 1 World                    1309425248000\n 2 Germany                   197463838000\n 3 Switzerland               183296295000\n 4 France                    123482590000\n 5 Belgium                   117396245000\n 6 United States of America  114868001000\n 7 United Kingdom            110713945000\n 8 Ireland                    96686923000\n 9 Italy                      76012918000\n10 Netherlands                59659401000\n# … with 210 more rows\n\nExploring Data\nLets plot the countries which were among the top 5 exporters each year and each of their performance over these 5 years.\n\n\nShow code\n\ntop5ExportersByYear = drugs %>% \n  filter(Exporter!=\"World\") %>% \n  group_by(Year) %>% \n  top_n(5, `Exports (USD)`) %>% \n  ungroup()\n\n\n\n\n\nShow code\n\ng = ggplot(data = top5ExportersByYear, aes(x = Year, y = `Exports (USD)`))\ng + geom_line(aes(color = Exporter)) + labs(title = 'Trend for top 5 exporters in the world over the years')\n\n\n\n\nEvaluating Top 10 exporters per Year. Excluding 2017 since we do not have numbers for total export in the world.\n\n\nShow code\n\ngetTop10ForYear = function(df){\n  top10ForYear = df %>% \n    filter(Exporter!=\"World\") %>% \n    top_n(10, `Exports (USD)`)\n  \n  othersExports = (df %>% filter(Exporter==\"World\") %>% select(`Exports (USD)`)) - (top10ForYear %>% summarise(Total = sum(`Exports (USD)`)))\n  \n  YEAR = df %>% select(Year) %>% unique() %>% .$Year\n  top10ForYear = top10ForYear %>% \n    add_row(Exporter = \"Others\", Year = YEAR, `Exports (USD)` = othersExports %>% .$`Exports (USD)`)\n  return(top10ForYear)\n}\nyearlyTop10s = drugs %>% \n  filter(Year != 2017) %>% \n  group_by(Year) %>% \n  do(getTop10ForYear(.))\nyearlyTop10s\n\n\n# A tibble: 44 x 3\n# Groups:   Year [4]\n   Exporter                  Year `Exports (USD)`\n   <chr>                    <dbl>           <dbl>\n 1 Germany                   2013     48493611000\n 2 Switzerland               2013     32337891000\n 3 Belgium                   2013     33329615000\n 4 France                    2013     27848920000\n 5 United States of America  2013     23098676000\n 6 United Kingdom            2013     20885936000\n 7 Ireland                   2013     18152573000\n 8 Italy                     2013     20898532000\n 9 Netherlands               2013     13480651000\n10 India                     2013     10313989000\n# … with 34 more rows\n\nWriting function to plot a Donut Chart for each year showing percentage export contribution for top 10 exporters of that year as compared to all others.\n\n\nShow code\n\nplotTop10 = function(df){\n  YEAR = df %>% select(Year) %>% unique() %>% .$Year\n  plotTitle = paste(\"World Medicine Export in\", YEAR, sep = \" \")\n  \n  df = df %>% \n    mutate(tot = sum(`Exports (USD)`),\n           prop = round(100*`Exports (USD)`/tot,2))\n  \n  p = ggplot(df, aes(x=2, y=prop, fill=Exporter)) + \n    geom_bar(stat=\"identity\") + \n    geom_text( aes(label = prop), position = position_stack(vjust = 0.5)) + \n    xlim(0.5, 2.5) +\n    coord_polar(theta = \"y\") +\n    labs(x=NULL, y=NULL) + \n    labs(fill=\"\") + \n    ggtitle(plotTitle) + \n    theme_bw() + \n    theme(plot.title = element_text(face=\"bold\",family=c(\"sans\"),size=15),\n          legend.text=element_text(size=10),\n          axis.ticks=element_blank(),\n          axis.text=element_blank(),\n          axis.title=element_blank(),\n          panel.grid=element_blank(),\n          panel.border=element_blank())\n  return(p)\n}\n\n\n\nPlotting the donuts for each year\n\n\nShow code\n\nplotTop10(yearlyTop10s %>% filter(Year==2013))\n\n\n\nShow code\n\nplotTop10(yearlyTop10s %>% filter(Year==2014))\n\n\n\nShow code\n\nplotTop10(yearlyTop10s %>% filter(Year==2015))\n\n\n\nShow code\n\nplotTop10(yearlyTop10s %>% filter(Year==2016))\n\n\n\n\nAs can be seen Germany remains the biggest exporter of Drugs and Medicines over the past 5 years.\n\n\n\n",
    "preview": "https://lh3.googleusercontent.com/5wIFfhutkaFsqnv2M72bnV_hFyJ_0d6y_Lu11O3U9Kx9XCD_WIGpMZCBl1iXJWzt63JsquXvi7TwNcNy6FGd_v5zq8PH2o7UhTqVIraM8Re5UGWb0myvjgzwsl080wnIXAwCx6s8oRkxXgIE5OzIar_Fw6kPcXJLIaTho3Q2lSWVac9p_U1vxNlbgWsf16aKc2lKWjkwHTaE6Hj2NnchUAXJ_6TpnoUiran--qVOKgkwQcCtEqo7DulTQxEuBZaQV9yoGTt6jbrgmwcquzR1OqTezSyLCzp_D6hK-GSkRYyvxAmRg2PvB1HedzzmiQ67y-32Z0bctMcUBigffgX3P_H9hO5v-K--dyDM-mBDHByiBkJ-ltrm0GdoMEARmE6E0kC4oy2afPX9_-PzDFhnK7_I-TXLt-1yO63abxRM2weynQ9qJHka6tyOiom3xTl1B8nkpwo1UfHkbF9MGOBER32zb86JVLmR9fJJZvLAMNjyYefxLb7BdP1CHeSvAK7CZMOkgdLJ3BQ7a4PAbKLUJTXPGiFaMRwmzbrx6OrUNNQnA3qF_bfW7ALEs3PnwDlXPJ3GBOnH8KOqfAU_ChQSW4rwlaqKa4d8O5mc_RMUNgSuTXYe6Q3TsXW7c_VPz7QLcC5spGONtyJQ9T6CRvAxXq2mtI5zRUdu=w750-h500-no",
    "last_modified": "2021-04-18T14:51:18-07:00",
    "input_file": {}
  },
  {
    "path": "posts/2018-02-15-the-winter-olympics-makeovermonday-2018-week7/",
    "title": "The Winter Olympics: MakeOverMonday 2018 Week7",
    "description": "Goal of this Visualization task is to create an alternative visualization\nto the Tableau's visualization for Winter Olympics data for different countries.",
    "author": [
      {
        "name": "Aditya Mangal",
        "url": "https://www.linkedin.com/in/adityamangal410/"
      }
    ],
    "date": "2018-02-15",
    "categories": [
      "MakeOverMonday"
    ],
    "contents": "\n\nContents\nIntroduction\nAnalysis\nCleaning up workspace and loading required libraries\nObtaining Data\nScrubbing data\nExploring Data\n\n\nIntroduction\nGoal of this Visualization task is to create an alternative visualization to the Tableau’s visualization for Winter Olympics data for different countries\nIn this blog post, I’m trying to generate a World Choropleth Map showing the total counts of medals for each country.\nAnalysis\nCleaning up workspace and loading required libraries\n\n\nShow code\n\nrm(list = ls())\n\n\n\n\n\nShow code\n\nlibrary(tidyverse) #Data Wrangling\nlibrary(httr)\nlibrary(readxl) #Data Ingestion\nlibrary(ggplot2) #Data Visualization\nlibrary(leaflet)\nlibrary(rgeos)\nlibrary(rgdal)\nlibrary(stringr)\n\n\n\nObtaining Data\nReading and viewing the dataset\n\n\nShow code\n\nGET(\"https://query.data.world/s/n5nc32oqhtb25hdt3vsa24rd4scs2w\", write_disk(tf <- tempfile(fileext = \".xlsx\")))\n\n\n\nShow code\n\nolympics = read_excel(tf)\n\n\n\n\n\nShow code\n\nolympics\n\n\n# A tibble: 2,865 x 9\n    Year Sport         Event        Country  Gender `Medal Rank` Medal\n   <dbl> <chr>         <chr>        <chr>    <chr>         <dbl> <chr>\n 1  1924 Bobsled       Men's Four/… Switzer… Men               1 gold \n 2  1924 Bobsled       Men's Four/… Britain  Men               2 silv…\n 3  1924 Bobsled       Men's Four/… Belgium  Men               3 bron…\n 4  1924 Cross-Countr… Men's 18 Ki… Norway   Men               1 gold \n 5  1924 Cross-Countr… Men's 18 Ki… Norway   Men               2 silv…\n 6  1924 Cross-Countr… Men's 18 Ki… Finland  Men               3 bron…\n 7  1924 Cross-Countr… Men's 50 Ki… Norway   Men               1 gold \n 8  1924 Cross-Countr… Men's 50 Ki… Norway   Men               2 silv…\n 9  1924 Cross-Countr… Men's 50 Ki… Norway   Men               3 bron…\n10  1924 Curling       Men's Curli… Britain  Men               1 gold \n# … with 2,855 more rows, and 2 more variables:\n#   Name of Athlete or Team <chr>, Age of Athlete <dbl>\n\nSummarizing and getting stats to better understand the dataset\n\n\nShow code\n\nolympics %>% \n  glimpse()\n\n\nRows: 2,865\nColumns: 9\n$ Year                      <dbl> 1924, 1924, 1924, 1924, 1924, 1924…\n$ Sport                     <chr> \"Bobsled\", \"Bobsled\", \"Bobsled\", \"…\n$ Event                     <chr> \"Men's Four/Five\", \"Men's Four/Fiv…\n$ Country                   <chr> \"Switzerland\", \"Britain\", \"Belgium…\n$ Gender                    <chr> \"Men\", \"Men\", \"Men\", \"Men\", \"Men\",…\n$ `Medal Rank`              <dbl> 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3…\n$ Medal                     <chr> \"gold\", \"silver\", \"bronze\", \"gold\"…\n$ `Name of Athlete or Team` <chr> \"Switzerland-1\", \"Britain-1\", \"Bel…\n$ `Age of Athlete`          <dbl> NA, NA, NA, 29, 24, 28, 29, 27, 24…\n\nShow code\n\nolympics %>% \n  summary()\n\n\n      Year         Sport              Event          \n Min.   :1924   Length:2865        Length:2865       \n 1st Qu.:1972   Class :character   Class :character  \n Median :1992   Mode  :character   Mode  :character  \n Mean   :1986                                        \n 3rd Qu.:2006                                        \n Max.   :2014                                        \n                                                     \n   Country             Gender            Medal Rank   \n Length:2865        Length:2865        Min.   :1.000  \n Class :character   Class :character   1st Qu.:1.000  \n Mode  :character   Mode  :character   Median :2.000  \n                                       Mean   :1.996  \n                                       3rd Qu.:3.000  \n                                       Max.   :3.000  \n                                                      \n    Medal           Name of Athlete or Team Age of Athlete \n Length:2865        Length:2865             Min.   :14.00  \n Class :character   Class :character        1st Qu.:22.00  \n Mode  :character   Mode  :character        Median :25.00  \n                                            Mean   :25.15  \n                                            3rd Qu.:28.00  \n                                            Max.   :42.00  \n                                            NA's   :692    \n\nScrubbing data\nAs per the dataset requirement, East and West Germany are to be grouped with Germany and Soviet Union and the 1992 Unified Team needs to be combined with Russia\n\n\nShow code\n\nolympics = olympics %>% \n  mutate(Country = recode(Country, \"Soviet Union\" = \"Russia\", \"Unified Team\" = \"Russia\",\n                          \"East Germany\" = \"Germany\", \"West Germany\" = \"Germany\"))\n\n\n\nReading in the ISO-3166 country codes dataset in order to generate the choropleth\n\n\nShow code\n\ncountryCodes = read_csv(\"https://raw.githubusercontent.com/lukes/ISO-3166-Countries-with-Regional-Codes/master/all/all.csv\")\n\n\n\n\n\nShow code\n\ncountryCodes\n\n\n# A tibble: 249 x 11\n   name        `alpha-2` `alpha-3` `country-code` `iso_3166-2`  region\n   <chr>       <chr>     <chr>     <chr>          <chr>         <chr> \n 1 Afghanistan AF        AFG       004            ISO 3166-2:AF Asia  \n 2 Åland Isla… AX        ALA       248            ISO 3166-2:AX Europe\n 3 Albania     AL        ALB       008            ISO 3166-2:AL Europe\n 4 Algeria     DZ        DZA       012            ISO 3166-2:DZ Africa\n 5 American S… AS        ASM       016            ISO 3166-2:AS Ocean…\n 6 Andorra     AD        AND       020            ISO 3166-2:AD Europe\n 7 Angola      AO        AGO       024            ISO 3166-2:AO Africa\n 8 Anguilla    AI        AIA       660            ISO 3166-2:AI Ameri…\n 9 Antarctica  AQ        ATA       010            ISO 3166-2:AQ <NA>  \n10 Antigua an… AG        ATG       028            ISO 3166-2:AG Ameri…\n# … with 239 more rows, and 5 more variables: sub-region <chr>,\n#   intermediate-region <chr>, region-code <chr>,\n#   sub-region-code <chr>, intermediate-region-code <chr>\n\nJoining the 2 datasets and verifying if any country name mismatch happening in the 2.\n\n\nShow code\n\nolympics %>% \n  left_join(countryCodes, by=c(\"Country\" = \"name\")) %>% \n  filter(is.na(`alpha-3`)) %>% \n  select(Country) %>% \n  unique()\n\n\n# A tibble: 8 x 1\n  Country       \n  <chr>         \n1 Britain       \n2 United States \n3 Czechoslovakia\n4 Russia        \n5 North Korea   \n6 Yugoslavia    \n7 South Korea   \n8 Czech Republic\n\nLooks like above 7 countries do not have a corresponding entry in the countryCodes dataset. Lets try to find out the corresponding names for each of the 7 in the countryCodes dataset.\n\n\nShow code\n\ncountryCodes %>% \n  filter(str_detect(str_to_lower(name), \"britain\")) #United Kingdom of Great Britain and Northern Ireland\n\n\n# A tibble: 1 x 11\n  name          `alpha-2` `alpha-3` `country-code` `iso_3166-2` region\n  <chr>         <chr>     <chr>     <chr>          <chr>        <chr> \n1 United Kingd… GB        GBR       826            ISO 3166-2:… Europe\n# … with 5 more variables: sub-region <chr>,\n#   intermediate-region <chr>, region-code <chr>,\n#   sub-region-code <chr>, intermediate-region-code <chr>\n\nShow code\n\ncountryCodes %>% \n  filter(str_detect(str_to_lower(name), \"states\")) #United States of America\n\n\n# A tibble: 3 x 11\n  name          `alpha-2` `alpha-3` `country-code` `iso_3166-2` region\n  <chr>         <chr>     <chr>     <chr>          <chr>        <chr> \n1 Micronesia (… FM        FSM       583            ISO 3166-2:… Ocean…\n2 United State… US        USA       840            ISO 3166-2:… Ameri…\n3 United State… UM        UMI       581            ISO 3166-2:… Ocean…\n# … with 5 more variables: sub-region <chr>,\n#   intermediate-region <chr>, region-code <chr>,\n#   sub-region-code <chr>, intermediate-region-code <chr>\n\nShow code\n\ncountryCodes %>% \n  filter(str_detect(str_to_lower(name), \"czech\")) #Czech Republic\n\n\n# A tibble: 1 x 11\n  name    `alpha-2` `alpha-3` `country-code` `iso_3166-2`  region\n  <chr>   <chr>     <chr>     <chr>          <chr>         <chr> \n1 Czechia CZ        CZE       203            ISO 3166-2:CZ Europe\n# … with 5 more variables: sub-region <chr>,\n#   intermediate-region <chr>, region-code <chr>,\n#   sub-region-code <chr>, intermediate-region-code <chr>\n\nShow code\n\ncountryCodes %>% \n  filter(str_detect(str_to_lower(name), \"russia\")) #Russian Federation\n\n\n# A tibble: 1 x 11\n  name          `alpha-2` `alpha-3` `country-code` `iso_3166-2` region\n  <chr>         <chr>     <chr>     <chr>          <chr>        <chr> \n1 Russian Fede… RU        RUS       643            ISO 3166-2:… Europe\n# … with 5 more variables: sub-region <chr>,\n#   intermediate-region <chr>, region-code <chr>,\n#   sub-region-code <chr>, intermediate-region-code <chr>\n\nShow code\n\ncountryCodes %>% \n  filter(str_detect(str_to_lower(name), \"korea\")) #Korea (Democratic People's Republic of) = North Korea, Korea (Republic of) = South Korea\n\n\n# A tibble: 2 x 11\n  name          `alpha-2` `alpha-3` `country-code` `iso_3166-2` region\n  <chr>         <chr>     <chr>     <chr>          <chr>        <chr> \n1 Korea (Democ… KP        PRK       408            ISO 3166-2:… Asia  \n2 Korea, Repub… KR        KOR       410            ISO 3166-2:… Asia  \n# … with 5 more variables: sub-region <chr>,\n#   intermediate-region <chr>, region-code <chr>,\n#   sub-region-code <chr>, intermediate-region-code <chr>\n\nShow code\n\ncountryCodes %>% \n  filter(str_detect(str_to_lower(name), \"yugo\")) #Macedonia (the former Yugoslav Republic of)\n\n\n# A tibble: 0 x 11\n# … with 11 variables: name <chr>, alpha-2 <chr>, alpha-3 <chr>,\n#   country-code <chr>, iso_3166-2 <chr>, region <chr>,\n#   sub-region <chr>, intermediate-region <chr>, region-code <chr>,\n#   sub-region-code <chr>, intermediate-region-code <chr>\n\nRenaming mismatched countries in olympic dataset based on countryCodes dataset.\n\n\nShow code\n\nolympics = olympics %>% \n  mutate(Country = recode(Country,\n                          \"Britain\" = \"United Kingdom of Great Britain and Northern Ireland\",\n                          \"United States\" = \"United States of America\",\n                          \"Czechoslovakia\" = \"Czech Republic\",\n                          \"Russia\" = \"Russian Federation\",\n                          \"North Korea\" = \"Korea (Democratic People's Republic of)\",\n                          \"South Korea\" = \"Korea (Republic of)\",\n                          \"Yugoslavia\" = \"Macedonia (the former Yugoslav Republic of)\"))\n\n\n\nJoining and viewing the 2 datasets\n\n\nShow code\n\nolympics = olympics %>% \n  left_join(countryCodes, by=c(\"Country\" = \"name\"))\nolympics\n\n\n# A tibble: 2,865 x 19\n    Year Sport     Event    Country          Gender `Medal Rank` Medal\n   <dbl> <chr>     <chr>    <chr>            <chr>         <dbl> <chr>\n 1  1924 Bobsled   Men's F… Switzerland      Men               1 gold \n 2  1924 Bobsled   Men's F… United Kingdom … Men               2 silv…\n 3  1924 Bobsled   Men's F… Belgium          Men               3 bron…\n 4  1924 Cross-Co… Men's 1… Norway           Men               1 gold \n 5  1924 Cross-Co… Men's 1… Norway           Men               2 silv…\n 6  1924 Cross-Co… Men's 1… Finland          Men               3 bron…\n 7  1924 Cross-Co… Men's 5… Norway           Men               1 gold \n 8  1924 Cross-Co… Men's 5… Norway           Men               2 silv…\n 9  1924 Cross-Co… Men's 5… Norway           Men               3 bron…\n10  1924 Curling   Men's C… United Kingdom … Men               1 gold \n# … with 2,855 more rows, and 12 more variables:\n#   Name of Athlete or Team <chr>, Age of Athlete <dbl>,\n#   alpha-2 <chr>, alpha-3 <chr>, country-code <chr>,\n#   iso_3166-2 <chr>, region <chr>, sub-region <chr>,\n#   intermediate-region <chr>, region-code <chr>,\n#   sub-region-code <chr>, intermediate-region-code <chr>\n\nAggregating per country to find the total number of medals for each country and its corresponding alpha-3 code.\n\n\nShow code\n\nTotalMedalsPerCountry = olympics %>% \n  group_by(Country, `alpha-3`) %>% \n  summarise(TotalMedals = n()) %>% \n  rename(Code = `alpha-3`)\nTotalMedalsPerCountry\n\n\n# A tibble: 39 x 3\n# Groups:   Country [39]\n   Country        Code  TotalMedals\n   <chr>          <chr>       <int>\n 1 Australia      AUS            12\n 2 Austria        AUT           218\n 3 Belarus        BLR            15\n 4 Belgium        BEL             5\n 5 Bulgaria       BGR             6\n 6 Canada         CAN           170\n 7 China          CHN            53\n 8 Croatia        HRV            11\n 9 Czech Republic <NA>           49\n10 Denmark        DNK             1\n# … with 29 more rows\n\nLets see the top countries based on total number of medals\n\n\nShow code\n\nTotalMedalsPerCountry %>% \n  arrange(desc(TotalMedals))\n\n\n# A tibble: 39 x 3\n# Groups:   Country [39]\n   Country                  Code  TotalMedals\n   <chr>                    <chr>       <int>\n 1 Germany                  DEU           377\n 2 Russian Federation       RUS           341\n 3 Norway                   NOR           329\n 4 United States of America USA           282\n 5 Austria                  AUT           218\n 6 Canada                   CAN           170\n 7 Finland                  FIN           161\n 8 Sweden                   SWE           144\n 9 Switzerland              CHE           138\n10 Italy                    ITA           114\n# … with 29 more rows\n\nGermany obtained the most number of medals (377) closely followed by Russia with (341)\nExploring Data\nLets plot the above data on a map using leaflet.\nLoading shape file data set from World Borders Dataset.\n\n\nShow code\n\nshape = readOGR(\"the-winter-olympics-makeovermonday-2018-week7/TM_WORLD_BORDERS_SIMPL-0.3/TM_WORLD_BORDERS_SIMPL-0.3.shp\")\n\n\nOGR data source with driver: ESRI Shapefile \nSource: \"/Users/amangal/Documents/mygit/portfolio_distill/_posts/2018-02-15-the-winter-olympics-makeovermonday-2018-week7/the-winter-olympics-makeovermonday-2018-week7/TM_WORLD_BORDERS_SIMPL-0.3/TM_WORLD_BORDERS_SIMPL-0.3.shp\", layer: \"TM_WORLD_BORDERS_SIMPL-0.3\"\nwith 246 features\nIt has 11 fields\nInteger64 fields read as strings:  POP2005 \n\nShow code\n\nnames(shape)\n\n\n [1] \"FIPS\"      \"ISO2\"      \"ISO3\"      \"UN\"        \"NAME\"     \n [6] \"AREA\"      \"POP2005\"   \"REGION\"    \"SUBREGION\" \"LON\"      \n[11] \"LAT\"      \n\n\n\nShow code\n\nTotalMedalsPerCountry = TotalMedalsPerCountry %>% \n  left_join(tbl_df(shape@data), by = c(\"Code\"=\"ISO3\")) %>% \n  na.omit()\n\nTotalMedalsPerCountry = TotalMedalsPerCountry %>% \n  mutate(label = str_c(sep = \" - \", NAME, \"TotalMedals\", TotalMedals))\n\n\n\n\n\nShow code\n\nbins = c(0, 10, 20, 30, 50, 100, 150, 200, 300, Inf)\npal = colorBin(\"RdYlGn\", domain = TotalMedalsPerCountry$TotalMedals, bins = bins)\n\nTotalMedalsPerCountry %>% \n  leaflet() %>% \n  addTiles() %>% \n  setView(53.019815, 1.369002, zoom = 1) %>% \n  addCircles(~LON, ~LAT, label = ~label, color = ~pal(TotalMedals), weight = 10)\n\n\n\n{\"x\":{\"options\":{\"crs\":{\"crsClass\":\"L.CRS.EPSG3857\",\"code\":null,\"proj4def\":null,\"projectedBounds\":null,\"options\":{}}},\"calls\":[{\"method\":\"addTiles\",\"args\":[\"//{s}.tile.openstreetmap.org/{z}/{x}/{y}.png\",null,null,{\"minZoom\":0,\"maxZoom\":18,\"tileSize\":256,\"subdomains\":\"abc\",\"errorTileUrl\":\"\",\"tms\":false,\"noWrap\":false,\"zoomOffset\":0,\"zoomReverse\":false,\"opacity\":1,\"zIndex\":1,\"detectRetina\":false,\"attribution\":\"&copy; <a href=\\\"http://openstreetmap.org\\\">OpenStreetMap<\\/a> contributors, <a href=\\\"http://creativecommons.org/licenses/by-sa/2.0/\\\">CC-BY-SA<\\/a>\"}]},{\"method\":\"addCircles\",\"args\":[[-24.973,47.683,53.54,50.643,42.761,59.081,33.42,45.723,56.058,58.674,64.504,46.565,51.11,47.07,42.7,36.491,48.16,39.778,56.858,47.153,49.771,52.077,-42.634,61.152,52.125,45.844,61.988,48.707,46.124,40.227,62.011,46.861,49.016,53,39.622,41.75],[136.189,14.912,28.047,4.664,25.231,-109.433,106.514,16.693,9.264,25.793,26.272,2.55,9.851,19.134,12.8,139.068,67.301,126.451,25.641,9.555,6.088,5.389,172.235,8.74,19.401,24.969,96.689,19.491,14.827,-3.649,15.27,7.908,31.388,-1.6,-98.606,63.17],10,null,null,{\"interactive\":true,\"className\":\"\",\"stroke\":true,\"color\":[\"#F46D43\",\"#66BD63\",\"#F46D43\",\"#D73027\",\"#D73027\",\"#A6D96A\",\"#FFFFBF\",\"#F46D43\",\"#D73027\",\"#D73027\",\"#A6D96A\",\"#D9EF8B\",\"#1A9850\",\"#D73027\",\"#D9EF8B\",\"#FEE08B\",\"#D73027\",\"#D73027\",\"#D73027\",\"#D73027\",\"#D73027\",\"#D9EF8B\",\"#D73027\",\"#1A9850\",\"#FDAE61\",\"#D73027\",\"#1A9850\",\"#D73027\",\"#F46D43\",\"#D73027\",\"#D9EF8B\",\"#D9EF8B\",\"#D73027\",\"#FDAE61\",\"#66BD63\",\"#D73027\"],\"weight\":10,\"opacity\":0.5,\"fill\":true,\"fillColor\":[\"#F46D43\",\"#66BD63\",\"#F46D43\",\"#D73027\",\"#D73027\",\"#A6D96A\",\"#FFFFBF\",\"#F46D43\",\"#D73027\",\"#D73027\",\"#A6D96A\",\"#D9EF8B\",\"#1A9850\",\"#D73027\",\"#D9EF8B\",\"#FEE08B\",\"#D73027\",\"#D73027\",\"#D73027\",\"#D73027\",\"#D73027\",\"#D9EF8B\",\"#D73027\",\"#1A9850\",\"#FDAE61\",\"#D73027\",\"#1A9850\",\"#D73027\",\"#F46D43\",\"#D73027\",\"#D9EF8B\",\"#D9EF8B\",\"#D73027\",\"#FDAE61\",\"#66BD63\",\"#D73027\"],\"fillOpacity\":0.2},null,null,[\"Australia - TotalMedals - 12\",\"Austria - TotalMedals - 218\",\"Belarus - TotalMedals - 15\",\"Belgium - TotalMedals - 5\",\"Bulgaria - TotalMedals - 6\",\"Canada - TotalMedals - 170\",\"China - TotalMedals - 53\",\"Croatia - TotalMedals - 11\",\"Denmark - TotalMedals - 1\",\"Estonia - TotalMedals - 7\",\"Finland - TotalMedals - 161\",\"France - TotalMedals - 109\",\"Germany - TotalMedals - 377\",\"Hungary - TotalMedals - 6\",\"Italy - TotalMedals - 114\",\"Japan - TotalMedals - 45\",\"Kazakhstan - TotalMedals - 7\",\"Korea, Democratic People's Republic of - TotalMedals - 2\",\"Latvia - TotalMedals - 7\",\"Liechtenstein - TotalMedals - 9\",\"Luxembourg - TotalMedals - 2\",\"Netherlands - TotalMedals - 110\",\"New Zealand - TotalMedals - 1\",\"Norway - TotalMedals - 329\",\"Poland - TotalMedals - 20\",\"Romania - TotalMedals - 1\",\"Russia - TotalMedals - 341\",\"Slovakia - TotalMedals - 5\",\"Slovenia - TotalMedals - 15\",\"Spain - TotalMedals - 2\",\"Sweden - TotalMedals - 144\",\"Switzerland - TotalMedals - 138\",\"Ukraine - TotalMedals - 7\",\"United Kingdom - TotalMedals - 26\",\"United States - TotalMedals - 282\",\"Uzbekistan - TotalMedals - 1\"],{\"interactive\":false,\"permanent\":false,\"direction\":\"auto\",\"opacity\":1,\"offset\":[0,0],\"textsize\":\"10px\",\"textOnly\":false,\"className\":\"\",\"sticky\":true},null,null]}],\"setView\":[[1.369002,53.019815],1,[]],\"limits\":{\"lat\":[-42.634,64.504],\"lng\":[-109.433,172.235]}},\"evals\":[],\"jsHooks\":[]}\nAs can be clearly seen above, Norway and USA closely followed in the total medals ranking. Visualizing data on a map can provide a clear view of the overall data.\n\n\n\n",
    "preview": "https://lh3.googleusercontent.com/rH18DMGKl5FY_Oh9o6WIoCTt7bDkkwghTNZGDjX6WhqkiUkm8ZWDg5ZvbkQLmNVjPZwZ2ksaKnjAYR2bPiWkLkdhLTN5dLsKfoHNr4Qf6HhDGhVey6eb2hCCiipxs_IUyBewU4QudW7mtj8iNIiYWzp0L_My0ZfgFBAnV1dU5vKVVMm8JEZDzncNX_xuijhjc54OHlvJT7TOZ8Qkh-aG95OPVCWG2vCYN2HaSCC8jUXJ9iYvYam3GmFQ8fQs7kKRLCpRkQgNAvb0STu-5J1KVC3EIrrSIZEkwGCzlQb5E4ZbT2d3mEw8Mo921nq9CG6TvvFMQpKHdXbszn9tBFv25CjnPLwLJ_G1DNc_CbCcbNslhcJSnAvbJKGUPSTu8JHTBpx1NY25I-p5UcA-3pXl50vM4f2Jggcih-Urtr2DXOjpMqWIlwEHcETQ6VbUAQY4aIE71O-WWkJhxekBvIbc28dLE8NP7o7QwnPho6SVdwNuy7milDhI8mL_6FlQ0lDFrEHGdnK03vayfMsv3PWRrsondkCsyHYpW1a5ER9_3MdHTIn57ZdkpNY0eXYICp-3sg_-BSlZSYnWzVdJys7LXMcu4P5zAJXkKQzgEg17Byr_6gyJYDYbb4S1lnoZB4xAKkDxwV_-CWBCc3M6NV1i8MwWEJeS_GCR=w750-h420-no",
    "last_modified": "2021-04-18T14:37:29-07:00",
    "input_file": {}
  },
  {
    "path": "posts/2017-09-28-india-transportation-accidents-exploration-project/",
    "title": "India Transportation Accidents Exploration Project",
    "description": "With this project I will try to visualize and understand the traffic accident data for India as publicly accessible  [here](https://data.gov.in/)",
    "author": [
      {
        "name": "Aditya Mangal",
        "url": "https://www.linkedin.com/in/adityamangal410/"
      }
    ],
    "date": "2017-09-28",
    "categories": [
      "Projects"
    ],
    "contents": "\nProject Goals\nVisualize traffic information and find trends\nFind outliers and see if any valuable info can be dugout for each state or overall.\nTry to predict number of accidents or other useful information.\nI’ll put out notebooks related to the work as separate articles.\n\n\n\n",
    "preview": "https://lh3.googleusercontent.com/fruMUvRzmWjXTG00Bk3TNfbHfTBDEgWQcK2L9Feb7tQM0FCzSk8o-DybzHccDP0PrBljq2y9X-GZuRTQXrat5_D_y3S1amU22CXBo-UPzr7RPGLkRl_53xksS_dtB3A-TCbqHTwOrOufikQznE7-7X8AtMrM53cHCJnR99ob7h8v_CEEQLOdje2DCBwblUtr4Mofna7vFWo7x7vRapU5pcyigJI6Qahne2vYAQiCjXP1lr8vJUN2a4C9mbr9xqDzH2UaNsZwuqsr53lhusfa-e8EhD0gTMZdL0FACu2McPJNDnJEeBG4dMbdB5IscN6w6Z6577nnSu0nTk0AibdUuI429JGQB2nPFZqLfk5uNKOGd4txq6ZJZifE11L9qyoXIw7WGGPC37qkQPYA5hKuGSfUZGG-VixKWX0AU0FI219exef5i5eo4yDyTn2dLiDJprA6MwEm_31a4aA_pbIgGR1O6HML3xCaManQAOv-7N0m1t2X3IwfSj7yq2hSydvQIoiCg7tb5ifPgVSrgWAvN64Jwp2AADJU_a16fIyO5HXv2XFURXEpsKj4sr9zzFDLMdY3wE6yip0vnH09xumEYNyvOEp2zkC2jPYGP5MPCgYSOpwnFLpLPxy49RFKbXMTHtS8XKFiuxH6b_gpPqPUOLwgASVOm_aH=w750-h498-no",
    "last_modified": "2021-04-18T14:38:29-07:00",
    "input_file": {}
  }
]
